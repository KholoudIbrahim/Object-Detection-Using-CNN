# -*- coding: utf-8 -*-
"""object_detection2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-_cuT_hTYem0PY791pY8RgcidwiEASJ6
"""

# Import libraries
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
# Import Warnings 
import warnings
warnings.filterwarnings('ignore')
import pandas as pd
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
#from sklearn.cross_validation import train_test_split
# Import tensorflow as the backend for Keras
from keras import backend as K
K.set_image_data_format('channels_first')
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.layers.convolutional import Convolution2D, MaxPooling2D
# from keras.optimizers import SGD,RMSprop,adam

from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.optimizers import Adam
from keras.callbacks import TensorBoard
# Import required libraries for cnfusion matrix
from sklearn.metrics import classification_report,confusion_matrix
import itertools

import keras 
from keras.datasets import mnist
from keras.layers import Dense, Dropout, Flatten 
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K
import numpy as np
from tensorflow.keras.utils import to_categorical

model = Sequential() 
model.add(Conv2D(32, kernel_size=(3, 3), 
    strides=(1,1),
    padding="same",
    activation='relu', 
    input_shape=(128,128,1)))

model.add(Conv2D(32, (3, 3),strides=(1,1),padding="same", activation='relu')) 
model.add(MaxPooling2D(pool_size=(2, 2),padding="same"))
 
model.add(Flatten()) 
model.add(Dropout(0.5)) 
model.add(Dense(128, activation='relu')) 
model.add(Dropout(0.5)) 
model.add(Dense(7, activation='softmax'))

from google.colab import drive
drive.mount('/content/drive')

! pip install kaggle

! mkdir ~/.kaggle

! cp /content/drive/MyDrive/detection/kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

!kaggle kernels output pavansanagapati/simple-tutorial-on-object-recognition -p /path/to/dest

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/detection/

import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content/drive/MyDrive/detection/"

!kaggle datasets download -d pavansanagapati/images-dataset

! unzip images-dataset

# Define data path

data_dir_list = ['bike', 'cars','cats','dogs','flowers','horses','human']
data_dir_list

img_rows=128
img_cols=128
num_channel=1
num_epoch=100
# Define the number of classes
num_classes = 7
img_data_list=[]
for dataset in data_dir_list:
	img_list=os.listdir("/content/drive/MyDrive/detection/data"+'/'+ dataset)
	print ('Loaded the images of dataset-'+'{}\n'.format(dataset))
	for img in img_list:
		input_img=cv2.imread("/content/drive/MyDrive/detection/data" + '/'+ dataset + '/'+ img )
		input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)
		input_img_resize=cv2.resize(input_img,(128,128))
		img_data_list.append(input_img_resize)

img_data = np.array(img_data_list)
img_data = img_data.astype('float32')
img_data /= 255
print (img_data.shape)

if num_channel==1:
	if K.set_image_data_format=='channels_first':
		img_data= np.expand_dims(img_data, axis=1) 
		print (img_data.shape)
	else:
		img_data= np.expand_dims(img_data, axis=3) 
		print (img_data.shape)
		
else:
	if K.image_dim_ordering()=='channels_first':
		img_data=np.rollaxis(img_data,3,1)
		print (img_data.shape)

num_classes = 7
num_of_samples = img_data.shape[0]
labels = np.ones((num_of_samples,),dtype='int64')
labels[0:365]=0
labels[365:567]=1
labels[567:987]=2
labels[987:1189]=3
labels[1189:1399]=4
labels[1399:1601]=5
labels[1601:1803]=6
names = ['bike', 'cars', 'cats', 'dogs', 'flowers', 'horses', 'human']

Y = np_utils.to_categorical(labels, num_classes)

x,y = shuffle(img_data,Y, random_state=2)
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)

print("X_train shape = {}".format(X_train.shape))
print("X_test shape = {}".format(X_test.shape))

image = X_train[1203,:].reshape((128,128))
plt.imshow(image)
plt.show()

model = Sequential() 
model.add(Conv2D(64, kernel_size=(3, 3), 
    strides=(1,1),
    padding="same",
    activation='relu', 
    input_shape=(128,128,1)))

model.add(Conv2D(64, (3, 3),strides=(1,1),padding="same", activation='relu')) 
model.add(MaxPooling2D(pool_size=(2, 2),padding="same"))
model.add(Conv2D(128, (3, 3),strides=(1,1),padding="same", activation='relu')) 
model.add(Conv2D(128, (3, 3),strides=(1,1),padding="same", activation='relu')) 
model.add(MaxPooling2D(pool_size=(2, 2),padding="same"))
model.add(Conv2D(256, (3, 3),strides=(1,1),padding="same", activation='relu')) 
model.add(Conv2D(256, (3, 3),strides=(1,1),padding="same", activation='relu')) 
model.add(Conv2D(256, (3, 3),strides=(1,1),padding="same", activation='relu')) 
model.add(MaxPooling2D(pool_size=(2, 2),padding="same"))
 
model.add(Flatten()) 
model.add(Dropout(0.5)) 
model.add(Dense(1024, activation='relu')) 
model.add(Dropout(0.5))
model.add(Dense(256, activation='relu')) 
model.add(Dropout(0.5)) 
model.add(Dense(7, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=["accuracy"])

model.summary()

hist = model.fit(X_train, y_train, batch_size=32, epochs=100 ,verbose=1, validation_data=(X_test, y_test))

plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.legend(['Training', 'Validation'])
plt.title('Training and Validation losses')
plt.xlabel('epoch')
plt.ylabel('Loss')
# plt.ylim([0,1])

plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.legend(['Training', 'Validation'])
plt.title('Training and Validation accuracy')
plt.xlabel('epoch')
plt.ylabel('accuracy')
# plt.ylim([0,1])

